{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4282ee5",
   "metadata": {},
   "source": [
    "# Match preditor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce5c5da-3cb0-435e-8656-bcee946fa45c",
   "metadata": {},
   "source": [
    "## Environment Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920351ab",
   "metadata": {},
   "source": [
    "**Installing XGBoost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d3dc42b-d7e3-48bc-acee-eafdd32f9e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4cbacf4",
   "metadata": {},
   "source": [
    "**Import libaries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "361735e8-817b-409b-a674-b4d26a2034fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf0d6c49-cdfd-472e-9bf6-2ef161c3ae12",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "try:\n",
    "    from xgboost import XGBClassifier\n",
    "    HAS_XGB = True\n",
    "except ImportError:\n",
    "    HAS_XGB = False\n",
    "    print(\"XGBoost install error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ffd237-828e-43e3-a641-b4260ba61cbf",
   "metadata": {},
   "source": [
    "## 1. Helper methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceeeaaaa-2cdb-40e3-afdd-bebda932cbfa",
   "metadata": {},
   "source": [
    "These utility functions support preprocessing steps used throughout the project:\n",
    "- **normalize_squad_column(df)** - Ensures that all datasets use a consistent column name (Squad) for team identifiers, renaming the column if needed and cleaning whitespace.\n",
    "- **compute_form_score(last5)** - Converts a team’s last-five-matches string (e.g., “WDLWW”) into a numerical form score by mapping wins, draws, and losses to +1, 0, and −1 respectively.\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ee79b4a-3690-484d-a3b9-a2cd13b17871",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_squad_column(df):\n",
    "    if \"Squad\" in df.columns:\n",
    "        pass\n",
    "    elif \"Team\" in df.columns:\n",
    "        df = df.rename(columns={\"Team\": \"Squad\"})\n",
    "    else:\n",
    "        raise ValueError(f\"No Squad/Team column found: {df.columns.tolist()}\")\n",
    "    df[\"Squad\"] = df[\"Squad\"].astype(str).str.strip()\n",
    "    return df\n",
    "\n",
    "\n",
    "def compute_form_score(last5):\n",
    "    if not isinstance(last5, str):\n",
    "        return 0.0\n",
    "    mapping = {\"W\": 1, \"D\": 0, \"L\": -1}\n",
    "    return sum(mapping.get(ch, 0) for ch in last5.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f89a7cd-e07a-41ee-b107-2637487675df",
   "metadata": {},
   "source": [
    "## 2. Match-level dataset construction per season"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9ed002-69ca-45b5-9c1d-d1b1f3ef419c",
   "metadata": {},
   "source": [
    "The function below builds a complete match-level dataset for a given Premier League season by combining fixtures with corresponding team statistics.\n",
    "- **Load team statistics** - Reads the merged squad–team CSV, normalizes team names, and calculates a form score from each team’s last five matches.\n",
    "- **Load fixtures and derive outcomes** - Reads the season’s fixture list, converts goal columns to numeric values, computes goal difference, and assigns the match result as H (home win), A (away win), or D (draw).\n",
    "- **Merge home and away features** - Joins team-level stats onto each fixture, once for the home team and once for the away team, creating a full set of performance features for both sides.\n",
    "- **Add season metadata** - Labels each row with the season and assigns a season-specific weight so that more recent seasons contribute more to the model.\n",
    "\n",
    "This produces a unified, feature-rich match dataset for a single Premier League season."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "985d7548-9c5f-4a1c-bbd7-f3175b1bbe3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_match_dataset_for_season(season_dir, season_weight):\n",
    "    season_dir = Path(season_dir)\n",
    "    season_label = season_dir.name\n",
    "\n",
    "    # Team stats\n",
    "    stats_files = list(season_dir.glob(\"*squad_team_merged*.csv\"))\n",
    "    if not stats_files:\n",
    "        raise FileNotFoundError(f\"No *squad_team_merged*.csv in {season_dir}\")\n",
    "    stats = pd.read_csv(stats_files[0])\n",
    "    stats = normalize_squad_column(stats)\n",
    "\n",
    "    # Adding recent performance score from the last 5 games\n",
    "    if \"Last 5\" in stats.columns:\n",
    "        stats[\"form_score\"] = stats[\"Last 5\"].apply(compute_form_score)\n",
    "    else:\n",
    "        stats[\"form_score\"] = 0.0\n",
    "\n",
    "    # Fixtures\n",
    "    fix_files = list(season_dir.glob(\"*fixtures*.csv\"))\n",
    "    if not fix_files:\n",
    "        raise FileNotFoundError(f\"No *fixtures*.csv in {season_dir}\")\n",
    "    fixtures = pd.read_csv(fix_files[0])\n",
    "\n",
    "    fixtures[\"Home_Goals\"] = pd.to_numeric(fixtures[\"Home_Goals\"], errors=\"coerce\")\n",
    "    fixtures[\"Away_Goals\"] = pd.to_numeric(fixtures[\"Away_Goals\"], errors=\"coerce\")\n",
    "\n",
    "    fixtures[\"goal_diff\"] = fixtures[\"Home_Goals\"] - fixtures[\"Away_Goals\"]\n",
    "    fixtures[\"result\"] = np.where(\n",
    "        fixtures[\"goal_diff\"] > 0, \"H\",\n",
    "        np.where(fixtures[\"goal_diff\"] < 0, \"A\", \"D\")\n",
    "    )\n",
    "    fixtures[\"season\"] = season_label\n",
    "\n",
    "    # Merge home stats\n",
    "    home_stats = stats.add_prefix(\"home_\")\n",
    "    merged = fixtures.merge(\n",
    "        home_stats, left_on=\"Home_Team\", right_on=\"home_Squad\", how=\"left\"\n",
    "    )\n",
    "\n",
    "    # Merge away stats\n",
    "    away_stats = stats.add_prefix(\"away_\")\n",
    "    merged = merged.merge(\n",
    "        away_stats, left_on=\"Away_team\", right_on=\"away_Squad\",\n",
    "        how=\"left\", suffixes=(\"\", \"_dupAway\")\n",
    "    )\n",
    "\n",
    "    merged = merged.drop(columns=[\"home_Squad\", \"away_Squad\"], errors=\"ignore\")\n",
    "\n",
    "    # Season weights -> recent seasons are more important1\n",
    "    merged[\"season_weight\"] = season_weight\n",
    "\n",
    "    return merged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b0b9a1-9ef6-4873-b6cc-d53a7f35817a",
   "metadata": {},
   "source": [
    "## 3. Building the full multi-season dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d45bfd",
   "metadata": {},
   "source": [
    "The function below constructs the complete match-level dataset by loading and combining all available Premier League seasons from the project’s data folder.\n",
    "\n",
    "- **Identify all season folders** -  Scans the base data directory for subfolders that represent individual seasons, each containing the corresponding fixtures and team statistics.\n",
    "- **Apply season weights** - Newer seasons receive higher weights. This ensures that the model prioritizes more recent team performance trends.\n",
    "- **Build per-season datasets** - For each season directory, we call build_match_dataset_for_season() to generate a unified feature table of fixtures, results, and team-level stats.\n",
    "- **Combine into one dataset** - All season-specific DataFrames are concatenated into a single, large dataset used for training and evaluation.\n",
    "\n",
    "This produces the full historical dataset required for feature engineering and model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e434b76-edbf-4173-be7a-a0e7689ae0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_full_dataset(base_dir = \"CSV_files\"):\n",
    "    base = Path(base_dir)\n",
    "    season_dirs = sorted(base.glob(\"Season_*\"))\n",
    "    if not season_dirs:\n",
    "        raise ValueError(\"CSV_files doesn't contain the correct folder.\")\n",
    "\n",
    "    all_dfs = []\n",
    "    n = len(season_dirs)\n",
    "\n",
    "    for i, season_dir in enumerate(season_dirs):\n",
    "        weight = 0.6 + 0.4 * (i / (n - 1)) if n > 1 else 1.0\n",
    "        print(f\"{season_dir.name} -> weight = {weight:.2f}\")\n",
    "        df_season = build_match_dataset_for_season(season_dir, season_weight=weight)\n",
    "        all_dfs.append(df_season)\n",
    "\n",
    "    full = pd.concat(all_dfs, ignore_index=True)\n",
    "    return full"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b21b81b",
   "metadata": {},
   "source": [
    "## 4. Data preparation and feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92669e26",
   "metadata": {},
   "source": [
    "This section prepares the full dataset for model training by constructing meaningful numerical features and splitting the data into training and testing sets.\n",
    "- **Load and clean data** The multi-season dataset is built and rows with missing match results are removed.\n",
    "- **Create home–away difference features** For each numerical team statistic, we compute **home–away difference features** capturing the relative advantage of the home team for that match.\n",
    "- **Select model features** - Only the engineered columns are used as predictors, ensuring a consistent and fully numeric feature space.\n",
    "- **Prepare target labels and weights** - The match result (H, D, A) is used as the prediction target, and season weights are carried over to emphasize recent seasons.\n",
    "- **Train-test split** - The dataset is split into training and testing subsets (80/20) using stratification to preserve the overall distribution of match outcomes.\n",
    "\n",
    "This produces a clean and structured feature matrix ready for model development."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88cf1daf-9b31-4497-98f7-f75d1477d586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Season_2020-2021 -> weight = 0.60\n",
      "Season_2021-2022 -> weight = 0.68\n",
      "Season_2022-2023 -> weight = 0.76\n",
      "Season_2023-2024 -> weight = 0.84\n",
      "Season_2024-2025 -> weight = 0.92\n",
      "Season_2025-2026 -> weight = 1.00\n"
     ]
    }
   ],
   "source": [
    "full_df = build_full_dataset(\"../CSV_files\")\n",
    "full_df = full_df.dropna(subset=[\"result\"])\n",
    "\n",
    "for col in list(full_df.columns):\n",
    "    if col.startswith(\"home_\"):\n",
    "        base = col[5:]\n",
    "        away_col = \"away_\" + base\n",
    "        if away_col in full_df.columns:\n",
    "            if full_df[col].dtype != \"O\" and full_df[away_col].dtype != \"O\":\n",
    "                full_df[f\"diff_{base}\"] = full_df[col] - full_df[away_col]\n",
    "\n",
    "feature_cols = [\n",
    "    c for c in full_df.columns\n",
    "    if c.startswith(\"diff_\") and full_df[c].dtype != \"O\"\n",
    "]\n",
    "\n",
    "X = full_df[feature_cols]\n",
    "y = full_df[\"result\"].astype(str)\n",
    "w = full_df[\"season_weight\"]\n",
    "\n",
    "mask = X.notna().all(axis=1)\n",
    "X = X[mask]\n",
    "y = y[mask]\n",
    "w = w[mask]\n",
    "\n",
    "X_train, X_test, y_train, y_test, w_train, w_test = train_test_split(\n",
    "    X, y, w, test_size=0.2, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b07df6e",
   "metadata": {},
   "source": [
    "## 5. Training three prediction models: Logistic Regression, Random Forest, and XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eebaf5d",
   "metadata": {},
   "source": [
    "In this section we train three different machine-learning models to predict match outcomes (H/D/A) using the engineered match-level features:\n",
    "\n",
    "- **Logistic Regression** - A linear classifier with feature scaling and balanced class weights.\n",
    "Useful as a baseline model to evaluate linear separability in the data.\n",
    "- **Random Forest** - A non-linear ensemble of decision trees capable of capturing complex interactions between features.\n",
    "Trained with class balancing and 500 trees for stable predictions.\n",
    "- **XGBoost** - A gradient-boosted tree model well-suited for multi-class classification and structured tabular data.\n",
    "Labels are encoded numerically for training, and sample weights are applied to emphasize recent seasons.\n",
    "\n",
    "Each model is trained using the weighted training set and evaluated on the held-out test data.\n",
    "The trained models are stored in the MODELS dictionary for later comparison and prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec0c210e-e20a-4d8a-9501-68de94dc68e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogReg accuracy: 0.5098522167487685\n",
      "RandomForest accuracy: 0.5788177339901478\n",
      "XGBoost accuracy: 0.5492610837438424\n"
     ]
    }
   ],
   "source": [
    "MODELS = {}\n",
    "\n",
    "# Logistic Regression\n",
    "logreg_model = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    LogisticRegression(\n",
    "        max_iter=2000,\n",
    "        class_weight=\"balanced\",\n",
    "        random_state=42,\n",
    "    )\n",
    ")\n",
    "logreg_model.fit(X_train, y_train, logisticregression__sample_weight=w_train)\n",
    "print(\"LogReg accuracy:\", logreg_model.score(X_test, y_test))\n",
    "MODELS[\"logreg\"] = logreg_model\n",
    "\n",
    "# RandomForest\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=500,\n",
    "    max_depth=None,\n",
    "    class_weight=\"balanced\",\n",
    "    random_state=42,\n",
    ")\n",
    "rf_model.fit(X_train, y_train, sample_weight=w_train)\n",
    "print(\"RandomForest accuracy:\", rf_model.score(X_test, y_test))\n",
    "MODELS[\"rf\"] = rf_model\n",
    "\n",
    "# XGBoost\n",
    "if HAS_XGB:\n",
    "    # labels to values\n",
    "    label_to_int = {\"A\": 0, \"D\": 1, \"H\": 2}\n",
    "    int_to_label = {v: k for k, v in label_to_int.items()}\n",
    "\n",
    "    y_train_xgb = y_train.map(label_to_int).values\n",
    "    y_test_xgb = y_test.map(label_to_int).values\n",
    "\n",
    "    xgb_model = XGBClassifier(\n",
    "        n_estimators=500,\n",
    "        max_depth=6,\n",
    "        learning_rate=0.05,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        objective=\"multi:softprob\",\n",
    "        eval_metric=\"mlogloss\",\n",
    "        random_state=42,\n",
    "    )\n",
    "    xgb_model.fit(X_train, y_train_xgb, sample_weight=w_train)\n",
    "\n",
    "    y_pred_xgb = xgb_model.predict(X_test)\n",
    "    xgb_acc = (y_pred_xgb == y_test_xgb).mean()\n",
    "    print(\"XGBoost accuracy:\", xgb_acc)\n",
    "\n",
    "    MODELS[\"xgb\"] = xgb_model\n",
    "else:\n",
    "    xgb_model = None\n",
    "    label_to_int = None\n",
    "    int_to_label = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a9d366",
   "metadata": {},
   "source": [
    "## 6. Generating match predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1729496",
   "metadata": {},
   "source": [
    "This section includes the utilities required to generate match-outcome probabilities for any future fixture using the trained models.\n",
    "- **Load latest team statistics** -  Retrieves the most recent team-level data and computes form indicators to ensure predictions rely on up-to-date performance information.\n",
    "- **Construct feature inputs for a match** - Given a home and away team, prepares the full engineered feature vector (e.g., statistical differences) in the same structure used during model training.\n",
    "- **Run predictions with a selected model**- Applies any trained model to the constructed feature vector and returns standardised probabilities for a home win, draw, or away win.\n",
    "- **Ensemble prediction** - Combines the outputs of several models using predefined weights to produce a more stable and robust overall prediction.\n",
    "\n",
    "These components enable real-time match forecasting and form the bridge between the trained models and the probability outputs used in analysis and visualisations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25e5790e-04a1-4e89-b226-b87ed19bc17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_latest_team_stats(base_dir = \"../CSV_files\"):\n",
    "    base = Path(base_dir)\n",
    "    season_dirs = sorted(base.glob(\"Season_*\"))\n",
    "    if not season_dirs:\n",
    "        raise ValueError(f\"No Season_* folders found under {base}\")\n",
    "    latest = season_dirs[-1]\n",
    "    stats_file = list(latest.glob(\"*squad_team_merged*.csv\"))[0]\n",
    "    stats = pd.read_csv(stats_file)\n",
    "    stats = normalize_squad_column(stats)\n",
    "    if \"Last 5\" in stats.columns:\n",
    "        stats[\"form_score\"] = stats[\"Last 5\"].apply(compute_form_score)\n",
    "    else:\n",
    "        stats[\"form_score\"] = 0.0\n",
    "    return stats\n",
    "\n",
    "\n",
    "LATEST_STATS = load_latest_team_stats()\n",
    "\n",
    "\n",
    "def build_feature_row_for_prediction(home_team, away_team):\n",
    "    home = LATEST_STATS[LATEST_STATS[\"Squad\"] == home_team]\n",
    "    away = LATEST_STATS[LATEST_STATS[\"Squad\"] == away_team]\n",
    "\n",
    "    if home.empty:\n",
    "        raise ValueError(f\"Home team '{home_team}' not found in latest stats.\")\n",
    "    if away.empty:\n",
    "        raise ValueError(f\"Away team '{away_team}' not found in latest stats.\")\n",
    "\n",
    "    home = home.reset_index(drop=True)\n",
    "    away = away.reset_index(drop=True)\n",
    "\n",
    "    data = {}\n",
    "    for col in feature_cols:\n",
    "        base = col[5:]\n",
    "        if base in home.columns and base in away.columns:\n",
    "            hv = home[base].iloc[0]\n",
    "            av = away[base].iloc[0]\n",
    "            if pd.api.types.is_numeric_dtype(type(hv)) and pd.api.types.is_numeric_dtype(type(av)):\n",
    "                try:\n",
    "                    data[col] = float(hv) - float(av)\n",
    "                except Exception:\n",
    "                    data[col] = np.nan\n",
    "            else:\n",
    "                data[col] = np.nan\n",
    "        else:\n",
    "            data[col] = np.nan\n",
    "\n",
    "    row = pd.DataFrame([data], columns=feature_cols)\n",
    "    return row\n",
    "\n",
    "\n",
    "# Predicing a single match with a certain model.\n",
    "def predict_match(home_team, away_team, model_name):\n",
    "\n",
    "    if model_name not in MODELS:\n",
    "        raise ValueError(f\"Unknown model '{model_name}'. Valid: {list(MODELS.keys())}\")\n",
    "\n",
    "    if home_team == away_team or home_team is None or away_team is None:\n",
    "        return \"Insert correct inputs.\"\n",
    "\n",
    "    row = build_feature_row_for_prediction(home_team, away_team)\n",
    "    model = MODELS[model_name]\n",
    "\n",
    "    probs = model.predict_proba(row)[0]\n",
    "    classes = model.classes_\n",
    "\n",
    "    if model_name == \"xgb\":\n",
    "        class_labels = [int_to_label[c] for c in classes]\n",
    "    else:\n",
    "        class_labels = list(classes)\n",
    "\n",
    "    prob_map = {cls: round(float(p), 3) for cls, p in zip(class_labels, probs)}\n",
    "\n",
    "    return {\n",
    "        \"home_team\": home_team,\n",
    "        \"away_team\": away_team,\n",
    "        \"model\": model_name,\n",
    "        \"probs\": {\n",
    "            \"home_win\": prob_map.get(\"H\", 0.0),\n",
    "            \"draw\": prob_map.get(\"D\", 0.0),\n",
    "            \"away_win\": prob_map.get(\"A\", 0.0),\n",
    "        },\n",
    "    }\n",
    "\n",
    "# Averages from current models with weights based on accuracy\n",
    "def predict_ensemble(home_team, away_team):\n",
    "\n",
    "    if home_team == away_team or home_team is None or away_team is None:\n",
    "        return \"Insert correct inputs.\"\n",
    "    \n",
    "    # Static weights for models based on accuracy, can be changed according to needs\n",
    "    weights = {\n",
    "        \"logreg\": 0.2,\n",
    "        \"rf\": 0.5,\n",
    "        \"xgb\": 0.3\n",
    "    }\n",
    "    \n",
    "    models = [\"logreg\", \"rf\", \"xgb\"]\n",
    "    probs_list = []\n",
    "    w_list = []\n",
    "    used_models = []\n",
    "\n",
    "    for m in models:\n",
    "        # If XGB is not available\n",
    "        if m not in MODELS:\n",
    "            continue\n",
    "\n",
    "        pred = predict_match(home_team, away_team, m)\n",
    "        probs_list.append(pred[\"probs\"])\n",
    "        w_list.append(weights[m])\n",
    "        used_models.append(m)\n",
    "\n",
    "    if len(probs_list) == 0:\n",
    "        raise ValueError(\"No valid models available for ensemble prediction.\")\n",
    "\n",
    "    # Normalizing (in case weight inputs are entered differently and don't sum up to 1.0)\n",
    "    w_arr = np.array(w_list, dtype=float)\n",
    "    w_arr = w_arr / w_arr.sum()\n",
    "\n",
    "    home_vals = np.array([p[\"home_win\"] for p in probs_list], dtype=float)\n",
    "    draw_vals = np.array([p[\"draw\"] for p in probs_list], dtype=float)\n",
    "    away_vals = np.array([p[\"away_win\"] for p in probs_list], dtype=float)\n",
    "\n",
    "    avg_home = round(float(np.sum(home_vals * w_arr)), 3)\n",
    "    avg_draw = round(float(np.sum(draw_vals * w_arr)), 3)\n",
    "    avg_away = round(float(np.sum(away_vals * w_arr)), 3)\n",
    "\n",
    "    return {\n",
    "        \"home_team\": home_team,\n",
    "        \"away_team\": away_team,\n",
    "        \"models_used\": used_models,\n",
    "        \"probs\": {\n",
    "            \"home_win\": avg_home,\n",
    "            \"draw\": avg_draw,\n",
    "            \"away_win\": avg_away\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871138e1",
   "metadata": {},
   "source": [
    "## Selecting Teams for Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf683b3f",
   "metadata": {},
   "source": [
    "This section lets you specify any valid Premier League teams to generate a match prediction.\n",
    "The model expects exact team names from the dataset, so the full list of available teams for the **2025/26 season** is provided below:\n",
    "\n",
    "**Valid Team Names (2025/26 season):**\n",
    "Arsenal, Aston Villa, Bournemouth, Brentford, Brighton, Burnley, Chelsea, Crystal Palace, Everton, Fulham,\n",
    "Leeds United, Liverpool, Manchester City, Manchester Utd, Newcastle Utd, Nott’ham Forest,\n",
    "Sunderland, Tottenham, West Ham, Wolves\n",
    "\n",
    "You can set:\n",
    "- **home_team** — the home side\n",
    "- **away_team** — the away side\n",
    "\n",
    "Once both teams are selected, you may generate predictions using any of the trained models:\n",
    "- **RANDOM FOREST**\n",
    "- **Logistic Regression**\n",
    "- **XGBoost**\n",
    "- Or use the **ensemble method**, which combines all models into a weighted final prediction\n",
    "\n",
    "The resulting output displays the predicted probabilities for a home win, draw, and away win, allowing to compare how different models assess the same fixture and evaluate the confidence of each prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b44a610a-179b-46b5-9d53-4887d7687e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "home_team = \"Manchester Utd\"\n",
    "away_team = \"Manchester City\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4309621f",
   "metadata": {},
   "source": [
    "## RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9bfa1170-5798-4158-9d48-cb002350edc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'home_team': 'Manchester Utd',\n",
       " 'away_team': 'Manchester City',\n",
       " 'model': 'rf',\n",
       " 'probs': {'home_win': 0.314, 'draw': 0.308, 'away_win': 0.378}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_match(home_team, away_team, model_name=\"rf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b15df6",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c69f141-70c8-4df5-8f58-d4220e588ccd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'home_team': 'Manchester Utd',\n",
       " 'away_team': 'Manchester City',\n",
       " 'model': 'logreg',\n",
       " 'probs': {'home_win': 0.236, 'draw': 0.43, 'away_win': 0.334}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_match(home_team, away_team, model_name=\"logreg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675a9a91",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "750930eb-764e-48a8-b772-711a5420755f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'home_team': 'Manchester Utd',\n",
       " 'away_team': 'Manchester City',\n",
       " 'model': 'xgb',\n",
       " 'probs': {'home_win': 0.485, 'draw': 0.391, 'away_win': 0.125}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_match(home_team, away_team, model_name=\"xgb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5ee6cb",
   "metadata": {},
   "source": [
    "## Ensemble method(Weighted averages from predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "861400a9-683b-42ad-83cd-3106b1962fa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'home_team': 'Manchester Utd',\n",
       " 'away_team': 'Manchester City',\n",
       " 'models_used': ['logreg', 'rf', 'xgb'],\n",
       " 'probs': {'home_win': 0.35, 'draw': 0.357, 'away_win': 0.293}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_ensemble(home_team, away_team)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
