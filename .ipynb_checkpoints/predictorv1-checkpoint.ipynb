{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d3dc42b-d7e3-48bc-acee-eafdd32f9e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\karlj\\anaconda3\\lib\\site-packages (3.1.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\karlj\\anaconda3\\lib\\site-packages (from xgboost) (2.1.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\karlj\\anaconda3\\lib\\site-packages (from xgboost) (1.15.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "25e5790e-04a1-4e89-b226-b87ed19bc17d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Season_2020-2021 -> weight = 0.60\n",
      "Season_2021-2022 -> weight = 0.68\n",
      "Season_2022-2023 -> weight = 0.76\n",
      "Season_2023-2024 -> weight = 0.84\n",
      "Season_2024-2025 -> weight = 0.92\n",
      "Season_2025-2026 -> weight = 1.00\n",
      "LogReg accuracy: 0.5123762376237624\n",
      "RandomForest accuracy: 0.5767326732673267\n",
      "XGBoost accuracy: 0.5420792079207921\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# XGBoost\n",
    "try:\n",
    "    from xgboost import XGBClassifier\n",
    "    HAS_XGB = True\n",
    "except ImportError:\n",
    "    HAS_XGB = False\n",
    "    print(\"xgboost error\")\n",
    "\n",
    "\n",
    "# 1. Helper methods\n",
    "def normalize_squad_column(df):\n",
    "    if \"Squad\" in df.columns:\n",
    "        pass\n",
    "    elif \"Team\" in df.columns:\n",
    "        df = df.rename(columns={\"Team\": \"Squad\"})\n",
    "    else:\n",
    "        raise ValueError(f\"No Squad/Team column found: {df.columns.tolist()}\")\n",
    "    df[\"Squad\"] = df[\"Squad\"].astype(str).str.strip()\n",
    "    return df\n",
    "\n",
    "\n",
    "def compute_form_score(last5):\n",
    "    if not isinstance(last5, str):\n",
    "        return 0.0\n",
    "    mapping = {\"W\": 1, \"D\": 0, \"L\": -1}\n",
    "    return sum(mapping.get(ch, 0) for ch in last5.strip())\n",
    "\n",
    "\n",
    "# ==========================================================\n",
    "# 2. Ühe hooaja match-level dataset\n",
    "# ==========================================================\n",
    "def build_match_dataset_for_season(season_dir: Path, season_weight: float) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    season_dir: Path('CSV_files/Season_2025-2026')\n",
    "    Eeldab, et kaustas on:\n",
    "      - *squad_team_merged*.csv\n",
    "      - *fixtures*.csv\n",
    "    \"\"\"\n",
    "    season_dir = Path(season_dir)\n",
    "    season_label = season_dir.name\n",
    "\n",
    "    # --- team stats ---\n",
    "    stats_files = list(season_dir.glob(\"*squad_team_merged*.csv\"))\n",
    "    if not stats_files:\n",
    "        raise FileNotFoundError(f\"No *squad_team_merged*.csv in {season_dir}\")\n",
    "    stats = pd.read_csv(stats_files[0])\n",
    "    stats = normalize_squad_column(stats)\n",
    "\n",
    "    # lisa vormiskoor\n",
    "    if \"Last 5\" in stats.columns:\n",
    "        stats[\"form_score\"] = stats[\"Last 5\"].apply(compute_form_score)\n",
    "    else:\n",
    "        stats[\"form_score\"] = 0.0\n",
    "\n",
    "    # --- fixtures ---\n",
    "    fix_files = list(season_dir.glob(\"*fixtures*.csv\"))\n",
    "    if not fix_files:\n",
    "        raise FileNotFoundError(f\"No *fixtures*.csv in {season_dir}\")\n",
    "    fixtures = pd.read_csv(fix_files[0])\n",
    "\n",
    "    fixtures[\"Home_Goals\"] = pd.to_numeric(fixtures[\"Home_Goals\"], errors=\"coerce\")\n",
    "    fixtures[\"Away_Goals\"] = pd.to_numeric(fixtures[\"Away_Goals\"], errors=\"coerce\")\n",
    "\n",
    "    fixtures[\"goal_diff\"] = fixtures[\"Home_Goals\"] - fixtures[\"Away_Goals\"]\n",
    "    fixtures[\"result\"] = np.where(\n",
    "        fixtures[\"goal_diff\"] > 0, \"H\",\n",
    "        np.where(fixtures[\"goal_diff\"] < 0, \"A\", \"D\")\n",
    "    )\n",
    "    fixtures[\"season\"] = season_label\n",
    "\n",
    "    # --- merge home stats ---\n",
    "    home_stats = stats.add_prefix(\"home_\")\n",
    "    merged = fixtures.merge(\n",
    "        home_stats, left_on=\"Home_Team\", right_on=\"home_Squad\", how=\"left\"\n",
    "    )\n",
    "\n",
    "    # --- merge away stats ---\n",
    "    away_stats = stats.add_prefix(\"away_\")\n",
    "    merged = merged.merge(\n",
    "        away_stats, left_on=\"Away_team\", right_on=\"away_Squad\",\n",
    "        how=\"left\", suffixes=(\"\", \"_dupAway\")\n",
    "    )\n",
    "\n",
    "    merged = merged.drop(columns=[\"home_Squad\", \"away_Squad\"], errors=\"ignore\")\n",
    "\n",
    "    # hooaja kaal (uuem hooaeg saab suurema kaalu)\n",
    "    merged[\"season_weight\"] = season_weight\n",
    "\n",
    "    return merged\n",
    "\n",
    "\n",
    "# ==========================================================\n",
    "# 3. Kõigi hooaegade koondamine\n",
    "# ==========================================================\n",
    "def build_full_dataset(base_dir: str = \"CSV_files\") -> pd.DataFrame:\n",
    "    base = Path(base_dir)\n",
    "    season_dirs = sorted(base.glob(\"Season_*\"))\n",
    "    if not season_dirs:\n",
    "        raise ValueError(\"CSV_files kaustast ei leitud ühtegi Season_* kausta.\")\n",
    "\n",
    "    all_dfs = []\n",
    "    n = len(season_dirs)\n",
    "\n",
    "    for i, season_dir in enumerate(season_dirs):\n",
    "        # lineaarne kaal vahemikus ~0.6 ... 1.0\n",
    "        weight = 0.6 + 0.4 * (i / (n - 1)) if n > 1 else 1.0\n",
    "        print(f\"{season_dir.name} -> weight = {weight:.2f}\")\n",
    "        df_season = build_match_dataset_for_season(season_dir, season_weight=weight)\n",
    "        all_dfs.append(df_season)\n",
    "\n",
    "    full = pd.concat(all_dfs, ignore_index=True)\n",
    "    return full\n",
    "\n",
    "\n",
    "# ==========================================================\n",
    "# 4. Andmete ettevalmistus + feature engineering\n",
    "# ==========================================================\n",
    "full_df = build_full_dataset(\"CSV_files\")\n",
    "full_df = full_df.dropna(subset=[\"result\"])\n",
    "\n",
    "# teeme diff_ feature'id: home_* - away_*\n",
    "for col in list(full_df.columns):\n",
    "    if col.startswith(\"home_\"):\n",
    "        base = col[5:]\n",
    "        away_col = \"away_\" + base\n",
    "        if away_col in full_df.columns:\n",
    "            # väldime stringi tüüpi\n",
    "            if full_df[col].dtype != \"O\" and full_df[away_col].dtype != \"O\":\n",
    "                full_df[f\"diff_{base}\"] = full_df[col] - full_df[away_col]\n",
    "\n",
    "# feature'id = kõik diff_ numbrilised veerud\n",
    "feature_cols = [\n",
    "    c for c in full_df.columns\n",
    "    if c.startswith(\"diff_\") and full_df[c].dtype != \"O\"\n",
    "]\n",
    "\n",
    "X = full_df[feature_cols]\n",
    "y = full_df[\"result\"].astype(str)\n",
    "w = full_df[\"season_weight\"]\n",
    "\n",
    "# viskame välja read, kus mõni feature on NaN\n",
    "mask = X.notna().all(axis=1)\n",
    "X = X[mask]\n",
    "y = y[mask]\n",
    "w = w[mask]\n",
    "\n",
    "X_train, X_test, y_train, y_test, w_train, w_test = train_test_split(\n",
    "    X, y, w, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "\n",
    "# ==========================================================\n",
    "# 5. Treeni kolm mudelit: logreg, rf, xgb\n",
    "# ==========================================================\n",
    "MODELS = {}\n",
    "\n",
    "# --- Logistic Regression ---\n",
    "logreg_model = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    LogisticRegression(\n",
    "        max_iter=2000,\n",
    "        class_weight=\"balanced\",\n",
    "        random_state=42,\n",
    "    )\n",
    ")\n",
    "logreg_model.fit(X_train, y_train, logisticregression__sample_weight=w_train)\n",
    "print(\"LogReg accuracy:\", logreg_model.score(X_test, y_test))\n",
    "MODELS[\"logreg\"] = logreg_model\n",
    "\n",
    "# --- RandomForest ---\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=500,\n",
    "    max_depth=None,\n",
    "    class_weight=\"balanced\",\n",
    "    random_state=42,\n",
    ")\n",
    "rf_model.fit(X_train, y_train, sample_weight=w_train)\n",
    "print(\"RandomForest accuracy:\", rf_model.score(X_test, y_test))\n",
    "MODELS[\"rf\"] = rf_model\n",
    "\n",
    "# --- XGBoost (kui olemas) ---\n",
    "if HAS_XGB:\n",
    "    # kaardistame labelid arvudeks\n",
    "    label_to_int = {\"A\": 0, \"D\": 1, \"H\": 2}\n",
    "    int_to_label = {v: k for k, v in label_to_int.items()}\n",
    "\n",
    "    y_train_xgb = y_train.map(label_to_int).values\n",
    "    y_test_xgb = y_test.map(label_to_int).values\n",
    "\n",
    "    xgb_model = XGBClassifier(\n",
    "        n_estimators=500,\n",
    "        max_depth=6,\n",
    "        learning_rate=0.05,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        objective=\"multi:softprob\",\n",
    "        eval_metric=\"mlogloss\",\n",
    "        random_state=42,\n",
    "    )\n",
    "    xgb_model.fit(X_train, y_train_xgb, sample_weight=w_train)\n",
    "\n",
    "    y_pred_xgb = xgb_model.predict(X_test)\n",
    "    xgb_acc = (y_pred_xgb == y_test_xgb).mean()\n",
    "    print(\"XGBoost accuracy:\", xgb_acc)\n",
    "\n",
    "    MODELS[\"xgb\"] = xgb_model\n",
    "else:\n",
    "    xgb_model = None\n",
    "    label_to_int = None\n",
    "    int_to_label = None\n",
    "\n",
    "\n",
    "\n",
    "# ==========================================================\n",
    "# 6. Ennustamine (ilma hooaega ette andmata)\n",
    "# ==========================================================\n",
    "def load_latest_team_stats(base_dir: str = \"CSV_files\") -> pd.DataFrame:\n",
    "    base = Path(base_dir)\n",
    "    season_dirs = sorted(base.glob(\"Season_*\"))\n",
    "    latest = season_dirs[-1]  # kõige uuem hooaeg\n",
    "    stats_file = list(latest.glob(\"*squad_team_merged*.csv\"))[0]\n",
    "    stats = pd.read_csv(stats_file)\n",
    "    stats = normalize_squad_column(stats)\n",
    "    if \"Last 5\" in stats.columns:\n",
    "        stats[\"form_score\"] = stats[\"Last 5\"].apply(compute_form_score)\n",
    "    else:\n",
    "        stats[\"form_score\"] = 0.0\n",
    "    return stats\n",
    "\n",
    "\n",
    "LATEST_STATS = load_latest_team_stats()\n",
    "\n",
    "\n",
    "def build_feature_row_for_prediction(home_team: str, away_team: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Ehita üks feature-rida, millel on täpselt samad diff_ veerud,\n",
    "    millega mudel treeniti.\n",
    "    \"\"\"\n",
    "    home = LATEST_STATS[LATEST_STATS[\"Squad\"] == home_team]\n",
    "    away = LATEST_STATS[LATEST_STATS[\"Squad\"] == away_team]\n",
    "\n",
    "    if home.empty:\n",
    "        raise ValueError(f\"Home team '{home_team}' not found in latest stats.\")\n",
    "    if away.empty:\n",
    "        raise ValueError(f\"Away team '{away_team}' not found in latest stats.\")\n",
    "\n",
    "    home = home.reset_index(drop=True)\n",
    "    away = away.reset_index(drop=True)\n",
    "\n",
    "    data = {}\n",
    "    # feature_cols sisaldab midagi stiilis: diff_GF, diff_GA, diff_xG, ...\n",
    "    for col in feature_cols:\n",
    "        base = col[5:]  # 'diff_GF' -> 'GF'\n",
    "        if base in home.columns and base in away.columns:\n",
    "            hv = home[base].iloc[0]\n",
    "            av = away[base].iloc[0]\n",
    "            if pd.api.types.is_numeric_dtype(type(hv)) and pd.api.types.is_numeric_dtype(type(av)):\n",
    "                try:\n",
    "                    data[col] = float(hv) - float(av)\n",
    "                except Exception:\n",
    "                    data[col] = np.nan\n",
    "            else:\n",
    "                data[col] = np.nan\n",
    "        else:\n",
    "            data[col] = np.nan\n",
    "\n",
    "    row = pd.DataFrame([data], columns=feature_cols)\n",
    "    return row\n",
    "\n",
    "\n",
    "def predict_match2(home_team: str, away_team: str, model_name):\n",
    "    \"\"\"\n",
    "    Ennustab kodutiimi / viigi / võõrsiltiimi tõenäosused.\n",
    "    model_name: 'rf', 'logreg' või 'xgb' (kui xgboost olemas).\n",
    "    \"\"\"\n",
    "    if model_name not in MODELS:\n",
    "        raise ValueError(f\"Unknown model '{model_name}'. Valid: {list(MODELS.keys())}\")\n",
    "\n",
    "    row = build_feature_row_for_prediction(home_team, away_team)\n",
    "    model = MODELS[model_name]\n",
    "\n",
    "    probs = model.predict_proba(row)[0]\n",
    "    classes = model.classes_\n",
    "\n",
    "    if model_name == \"xgb\":\n",
    "        # classes on [0,1,2] -> tõlgime tagasi 'A','D','H'\n",
    "        class_labels = [int_to_label[c] for c in classes]\n",
    "    else:\n",
    "        # logreg ja rf kasutavad otse 'A','D','H'\n",
    "        class_labels = list(classes)\n",
    "\n",
    "    prob_map = {cls: float(p) for cls, p in zip(class_labels, probs)}\n",
    "\n",
    "    return {\n",
    "        \"home_team\": home_team,\n",
    "        \"away_team\": away_team,\n",
    "        \"model\": model_name,\n",
    "        \"probs\": {\n",
    "            \"home_win\": prob_map.get(\"H\", 0.0),\n",
    "            \"draw\": prob_map.get(\"D\", 0.0),\n",
    "            \"away_win\": prob_map.get(\"A\", 0.0),\n",
    "        },\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9bfa1170-5798-4158-9d48-cb002350edc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'home_team': 'Manchester City',\n",
       " 'away_team': 'Newcastle Utd',\n",
       " 'model': 'rf',\n",
       " 'probs': {'home_win': 0.632, 'draw': 0.216, 'away_win': 0.152}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# V2 RANDOM FOREST\n",
    "predict_match2(\"Manchester City\", \"Newcastle Utd\", model_name=\"rf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6c69f141-70c8-4df5-8f58-d4220e588ccd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'home_team': 'Manchester City',\n",
       " 'away_team': 'Newcastle Utd',\n",
       " 'model': 'logreg',\n",
       " 'probs': {'home_win': 0.5216974558399203,\n",
       "  'draw': 0.3266660768352799,\n",
       "  'away_win': 0.1516364673247998}}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# V2 LOGREG\n",
    "predict_match2(\"Manchester City\", \"Newcastle Utd\", model_name=\"logreg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "750930eb-764e-48a8-b772-711a5420755f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'home_team': 'Manchester City',\n",
       " 'away_team': 'Newcastle Utd',\n",
       " 'model': 'xgb',\n",
       " 'probs': {'home_win': 0.8080324530601501,\n",
       "  'draw': 0.14107152819633484,\n",
       "  'away_win': 0.05089602991938591}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# V2 XGB\n",
    "predict_match2(\"Manchester City\", \"Newcastle Utd\", model_name=\"xgb\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
